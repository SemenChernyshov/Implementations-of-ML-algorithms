{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HVyzwL9ByRhT"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gini_impurity(y: np.ndarray) -> float:\n",
        "    # G = 1 - sum(pk)^2\n",
        "    p1 = sum(y) / len(y)\n",
        "    p0 = 1 - p1\n",
        "    return 1 - p0**2 - p1**2\n",
        "\n",
        "\n",
        "def entropy(y: np.ndarray) -> float:\n",
        "    # entropy = - sum pk*log2(pk)\n",
        "    p1 = sum(y) / len(y)\n",
        "    p0 = 1 - p1\n",
        "    if p0 ==0:\n",
        "        return  - p1*np.log2(p1)\n",
        "    elif p1 == 0:\n",
        "        return  - p0*np.log2(p0)\n",
        "    return - p0*np.log2(p0) - p1*np.log2(p1)\n",
        "\n",
        "\n",
        "def inform_gain(X: np.ndarray, y: np.ndarray, threshold: float, criteria_func=entropy) -> float:\n",
        "    #IG(Q) = S0 - sum Ni*Si/N\n",
        "    S0 = criteria_func(y)\n",
        "    mask1 = (X <= threshold)\n",
        "    mask2 = (X > threshold)\n",
        "    S1 = criteria_func(y[mask1])\n",
        "    if sum(mask2) ==0:\n",
        "        S2 = 0\n",
        "    else:\n",
        "        S2 = criteria_func(y[mask2])\n",
        "    N1 = sum(mask1)\n",
        "    N2 = sum(mask2)\n",
        "    N = len(X)\n",
        "    return np.round(S0 - N1*S1/N - N2*S2/N,4)\n",
        "\n",
        "def get_best_threshold(X: np.ndarray, y: np.ndarray, criteria_func=entropy) -> (float, float):\n",
        "    assert X.ndim == 1\n",
        "    assert y.ndim == 1\n",
        "    best_threshold = 0\n",
        "    best_score = 0\n",
        "    for val in np.unique(X):\n",
        "        IG = inform_gain(X,y,val,criteria_func)\n",
        "        if IG >= best_score:\n",
        "            best_threshold = val\n",
        "            best_score = IG\n",
        "    return best_threshold, best_score\n",
        "\n",
        "def find_best_split(X, y, criteria_func=entropy):\n",
        "    assert X.ndim == 2\n",
        "    assert y.ndim == 1\n",
        "    best_feature = 0\n",
        "    best_score = 0\n",
        "    best_threshold = 0\n",
        "    n,m = X.shape\n",
        "    ### делаем цикл по всем фичам в X и находим для каждой лучший threshold и score.\n",
        "    ### Потом сравниваем с наилучшим (best)\n",
        "    for j in range(m):\n",
        "        thr, score = get_best_threshold(X[:,j], y, criteria_func)\n",
        "\n",
        "        if score >= best_score:\n",
        "            best_score = score\n",
        "            best_feature = j\n",
        "            best_threshold = thr\n",
        "\n",
        "    return best_feature, best_threshold, best_score\n",
        "\n",
        "class MyDecisionTreeClassifier():\n",
        "    def __init__(self, max_depth=4, criterion='entropy'):\n",
        "        self.max_depth = max_depth\n",
        "        self.criterion = criterion # 'entropy' or 'gini'\n",
        "        self.tree = {}\n",
        "        self._criteria_func = {\n",
        "            'gini': gini_impurity,\n",
        "            'entropy': entropy\n",
        "        }\n",
        "        self.count_of_features = 0\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "\n",
        "        split_feature, split_val, score = find_best_split(X,y,self._criteria_func[self.criterion])\n",
        "\n",
        "        # критерий остановки: если мы достигли нужной глубины или если скор оказался равен нулю\n",
        "        # технически со скором 0 нужно проверить потенциальную разбиваемость на след уровнях, но это сложно, так что пока так закостылим:)\n",
        "        if depth == self.max_depth or score == 0:\n",
        "            p1 = sum(y) / len(y)\n",
        "            p0 = 1 - p1\n",
        "            return {'leaf': True,\n",
        "                    'proba': [p0, p1]\n",
        "                   }\n",
        "\n",
        "        left_ids = X[:, split_feature] <= split_val\n",
        "        right_ids = X[:, split_feature] > split_val\n",
        "\n",
        "        left_tree  =  self._build_tree(X[left_ids], y[left_ids], depth + 1)\n",
        "        right_tree = self._build_tree(X[right_ids], y[right_ids], depth + 1)\n",
        "        return {'leaf': False,\n",
        "                'val': {'split_feature': split_feature,\n",
        "                        'split_val': split_val,\n",
        "                        'score': score},\n",
        "                'left': left_tree,\n",
        "                'right': right_tree}\n",
        "\n",
        "    def _predict_proba_obj(self, obj: np.array):\n",
        "        assert obj.ndim == 1\n",
        "\n",
        "        node = self.tree\n",
        "\n",
        "        ### необходимо спустится в нужную листовую ноду\n",
        "        while not node['leaf']:\n",
        "            if obj[node['val']['split_feature']] <= node['val']['split_val']:\n",
        "                node = node['left']\n",
        "            else:\n",
        "                node = node['right']\n",
        "\n",
        "        assert node['leaf'] == True\n",
        "        return node['proba']\n",
        "\n",
        "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
        "        self.count_of_features = X.shape[1]\n",
        "        self.tree = self._build_tree(X, y, depth=0)\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X: np.ndarray):\n",
        "        assert X.shape[1] == self.count_of_features\n",
        "        proba = []\n",
        "        for row in X:\n",
        "            proba.append(self._predict_proba_obj(row))\n",
        "        return np.array(proba)\n",
        "\n",
        "    def predict(self, X: np.ndarray): # получаем\n",
        "        assert X.shape[1] == self.count_of_features\n",
        "        proba = self.predict_proba(X)\n",
        "        return np.array(list(np.argmax(proba, axis=1)))\n"
      ],
      "metadata": {
        "id": "PliEQhKayVFg"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}